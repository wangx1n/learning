# java

## Reetrantlock是如何实现可重入的

https://blog.csdn.net/weixin_32281549/article/details/112350360

1. 通过cas操作置锁的state字段为1
2. 再次获取state时发现为1，置1失败
3. 置1失败后判断是否是当前线程获取的锁，是的话state+1
4. 释放时state为0时才能彻底释放锁

## ConcurrentHashMap

### 1. 数据结构

### 2. 参数

### 3. 源码

### 4. 扩容流程

### 5. CAS + synchronized

### 6. volatile



## 为什么要从永久代转变为元空间

　	1、字符串存在永久代中，容易出现性能问题和内存溢出。

　　2、类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。

　　3、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。

　　4、Oracle 可能会将HotSpot 与 JRockit 合二为一。



## java内存区域

https://github.com/Snailclimb/JavaGuide/blob/3965c02cc0f294b0bd3580df4868d5e396959e2e/Java%E7%9B%B8%E5%85%B3/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0.md#22-java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88



## GC ROOT 在哪里

- 所有Java线程当前活跃的栈帧里指向GC堆里的对象的引用；换句话说，当前所有正在被调用的方法的引用类型的参数/局部变量/临时值。
- VM的一些静态数据结构里指向GC堆里的对象的引用，例如说HotSpot VM里的Universe里有很多这样的引用。



## 标记清除、标记复制、标记整理

https://blog.csdn.net/weixin_38168947/article/details/109066221

##  指针碰撞、空闲列表

https://blog.csdn.net/hyman_c/article/details/103051359

内存规整用指针碰撞、不规整用空闲列表



# kafka

## kafka完全指南

https://www.cnblogs.com/sujing/p/10960832.html

### kafka是如何实现高性能的

https://zhuanlan.zhihu.com/p/106033054

1. 多分区

2. 顺序读写磁盘

3. 充分利用page cache（kafka是如何充分利用page cache的）https://blog.csdn.net/gx11251143/article/details/107620259

   1. pageCache是什么 平衡内存与磁盘速度的媒介

   2. kafka是怎么使用pageCache的 kafka写直接写pageCache, 最好读写速度匹配，做到空中接力，否则读磁盘影响线上

   3. pageCache参数 dirty_expire_centisecs 写入磁盘的速度 默认半分钟 pageCache被标记为dirty的话，超过这个时间写入磁盘

      dirty_background_ratio pageCache的总大小占内存空间的百分比，默认10%，超过异步写入磁盘

      dirty_ratio dirty page的总大小占总内存量的比例 默认20%, 超过这个比例，阻塞所有write，强制每个进程将自己的文件写入磁盘

4. 零拷贝（什么是零拷贝）https://www.cnblogs.com/zz-ksw/p/12801632.html

   1. mmap
   2. sendfile

   https://zhuanlan.zhihu.com/p/63626191 这篇将0拷贝讲的好一些



## 为什么要用kafka

1. 缓冲、削峰 ： 上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就可以按照自己的节奏进行慢慢处理。
2. 解耦 ： 项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。
3. 冗余 ： 可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。
4. 健壮性 ： 消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。
5. 异步通信 ： 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。



## 如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？

1.  partition在写入的时候可以指定需要写入的partition，如果有指定，则写入对应的partition。
2. 如果没有指定partition，但是设置了数据的key，则会根据key的值hash出一个partition。
3. 如果既没指定partition，又没有设置key，则会轮询选出一个partition。



## Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么

ISR:In-Sync Replicas 副本同步队列
AR:Assigned Replicas 所有副本
**ISR是由leader维护**，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。**AR=ISR+OSR**。



## kafka中的broker 是干什么的

broker 是消息的代理，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，然后进行业务处理，broker在中间起到一个代理保存消息的中转站。



## kafka中的 zookeeper 起到什么作用，可以不用zookeeper么

zookeeper 是一个分布式的协调组件，早期版本的kafka用zk做meta信息存储，consumer的消费状态，group的管理以及 offset的值。考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的**group coordination**协议，也减少了对zookeeper的依赖，

但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举controller 和 检测broker是否存活等等。



## kafka follower如何与leader同步数据

Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求All Alive Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用ISR的方式很好的均衡了确保数据不丢失以及吞吐率。Follower可以批量的从Leader复制数据，而且Leader充分利用磁盘顺序读以及send file(zero copy)机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了Follower与Leader的消息量差。



## 什么情况下一个 broker 会从 isr中踢出去

leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护 ，如果一个follower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除 。



## 为什么Kafka不支持读写分离？

在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。

Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:

(1)**数据一致性问题**。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。

(2)**延时问题**。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。



## Kafka中是怎么体现消息顺序性的？

kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.



## 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1

`offset + 1`



## kafka元数据都有哪些

- **服务器活动状态**
- **Topic和Topic的分区**
- **Partition都有哪些Replication**
- **哪个Replication是Leader**



